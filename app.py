import os
import argparse
from dotenv import load_dotenv
from reddit_scraper import scrape_reddit_user
from persona_chain import generate_user_persona
from utils import save_persona_to_file
from sentiment_analyzer import analyze_sentiment_and_behavior
from activity_analyzer import analyze_activity_timeline
from writing_style_analyzer import analyze_writing_style
from topic_analyzer import analyze_topics
from social_network_analyzer import analyze_social_interactions
from personality_analyzer import analyze_big_five_personality

# Load environment variables from .env
load_dotenv()

def run_basic_analysis(reddit_url: str):
    """Run basic persona generation"""
    print("ðŸ§  Reddit Persona Agent - Basic Analysis")
    
    # Step 1: Scrape Reddit data
    print("ðŸ” Scraping Reddit user data...")
    user_data = scrape_reddit_user(reddit_url)

    if not user_data["posts"] and not user_data["comments"]:
        print("âŒ No user data found. Please check the Reddit URL.")
        return

    # Step 2: Generate persona using LangChain LLM
    print("ðŸ§¬ Generating user persona...")
    persona_output = generate_user_persona(user_data)

    # Step 3: Save the persona to file
    username = reddit_url.strip("/").split("/")[-1]
    save_persona_to_file(username, persona_output)

    print(f"âœ… Persona created for user '{username}' in 'output/{username}_persona.txt'")
    return persona_output

def run_advanced_analysis(reddit_url: str):
    """Run comprehensive advanced analysis"""
    print("ðŸ§  Reddit Persona Agent - Advanced Analysis")
    
    # Step 1: Scrape Reddit data
    print("ðŸ” Scraping Reddit user data...")
    user_data = scrape_reddit_user(reddit_url)

    if not user_data["posts"] and not user_data["comments"]:
        print("âŒ No user data found. Please check the Reddit URL.")
        return

    username = reddit_url.strip("/").split("/")[-1]
    
    # Step 2: Run all analyses
    print("ðŸ§¬ Generating comprehensive analysis...")
    
    print("  ðŸ“Š Basic persona generation...")
    persona_output = generate_user_persona(user_data)
    
    print("  ðŸ˜Š Sentiment & behavioral analysis...")
    sentiment_analysis = analyze_sentiment_and_behavior(user_data)
    
    print("  â° Activity timeline analysis...")
    activity_analysis = analyze_activity_timeline(user_data)
    
    print("  ðŸ“ Writing style analysis...")
    writing_analysis = analyze_writing_style(user_data)
    
    print("  ðŸ·ï¸ Topic modeling...")
    topic_analysis = analyze_topics(user_data)
    
    print("  ðŸ‘¥ Social network analysis...")
    social_analysis = analyze_social_interactions(user_data)
    
    print("  ðŸŽ­ Personality analysis...")
    personality_analysis = analyze_big_five_personality(user_data)
    
    # Step 3: Compile comprehensive report
    print("ðŸ“‹ Compiling comprehensive report...")
    comprehensive_report = compile_comprehensive_report(
        username, persona_output, sentiment_analysis, activity_analysis,
        writing_analysis, topic_analysis, social_analysis, personality_analysis
    )
    
    # Step 4: Save comprehensive report
    save_persona_to_file(f"{username}_comprehensive", comprehensive_report)
    
    print(f"âœ… Comprehensive analysis completed for user '{username}'")
    print(f"ðŸ“„ Basic persona: 'output/{username}_persona.txt'")
    print(f"ðŸ“Š Comprehensive report: 'output/{username}_comprehensive_persona.txt'")
    
    return comprehensive_report

def compile_comprehensive_report(username, persona, sentiment, activity, writing, topics, social, personality):
    """Compile all analyses into a comprehensive report"""
    report = f"""
# ðŸ§  COMPREHENSIVE REDDIT USER ANALYSIS: {username}
Generated by Reddit Persona Agent

## ðŸ“‹ BASIC PERSONA
{persona}

## ðŸ“Š ADVANCED ANALYTICS SUMMARY

### ðŸŽ­ PERSONALITY PROFILE (Big Five)
"""
    
    if personality.get('personality_scores'):
        for trait, data in personality['personality_scores'].items():
            report += f"- **{trait.title()}**: {data['score']:.0f}/100 ({data['level']})\n"
    
    report += f"\n### ðŸ“ WRITING STYLE INSIGHTS\n"
    for insight in writing.get('writing_insights', []):
        report += f"- {insight}\n"
    
    report += f"\n### ðŸ·ï¸ MAIN TOPICS\n"
    if topics.get('topic_keywords'):
        for topic, keywords in list(topics['topic_keywords'].items())[:5]:
            report += f"- **{topic}**: {', '.join(keywords[:3])}\n"
    
    report += f"\n### ðŸ‘¥ SOCIAL BEHAVIOR\n"
    for insight in social.get('network_insights', []):
        report += f"- {insight}\n"
    
    report += f"\n### â° ACTIVITY PATTERNS\n"
    for insight in activity.get('activity_insights', []):
        report += f"- {insight}\n"
    
    report += f"\n### ðŸ˜Š EMOTIONAL PROFILE\n"
    if sentiment.get('emotion_analysis'):
        for emotion, percentage in sentiment['emotion_analysis'].items():
            if percentage > 5:  # Only show significant emotions
                report += f"- **{emotion.title()}**: {percentage:.1f}%\n"
    
    report += f"\n---\n*Generated by Reddit Persona Agent - Advanced Analytics*"
    
    return report

def main():
    parser = argparse.ArgumentParser(description='Reddit Persona Agent')
    parser.add_argument('--url', type=str, help='Reddit user profile URL')
    parser.add_argument('--advanced', action='store_true', help='Run advanced comprehensive analysis')
    
    args = parser.parse_args()
    
    if args.url:
        reddit_url = args.url
    else:
        reddit_url = input("ðŸ”— Enter the Reddit user profile URL: ").strip()
    
    if args.advanced:
        run_advanced_analysis(reddit_url)
    else:
        # Ask user for analysis type
        print("\nChoose analysis type:")
        print("1. Basic Persona Generation")
        print("2. Advanced Comprehensive Analysis")
        choice = input("Enter choice (1 or 2): ").strip()
        
        if choice == "2":
            run_advanced_analysis(reddit_url)
        else:
            run_basic_analysis(reddit_url)

if __name__ == "__main__":
    main()
